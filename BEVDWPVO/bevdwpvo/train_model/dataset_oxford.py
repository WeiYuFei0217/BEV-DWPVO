import os
import cv2
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader, ConcatDataset
from torchvision import transforms
import struct
import matplotlib.pyplot as plt
import transforms3d.euler as euler
from PIL import Image
import numpy as np
import random
import sys
from typing import List
from sklearn.neighbors import KDTree
import copy
import pickle
import matplotlib.pyplot as plt
import transforms3d as t3d
from tqdm import tqdm

from utils import read_lidar_poses_RPY, find_nearest_ndx, read_ts_file, load_velodyne_raw, load_velodyne_binary, velodyne_raw_to_pointcloud
# from utils import *
from config_files import *

BAYER_STEREO = 'gbrg'
BAYER_MONO = 'rggb'


# concantate pointclouds generated by the left and right lidar
def pc_concantate(pc_left, pc_right, extrinsics_dir=os.path.join(os.path.dirname(__file__), 'extrinsics')):
    '''velodyne'''
    with open(os.path.join(extrinsics_dir, 'ins.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        T_ins_matrix = build_se3_transform([float(x) for x in extrinsics.split(' ')])     
    with open(os.path.join(extrinsics_dir, 'velodyne_left.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        left_T = build_se3_transform([float(x) for x in extrinsics.split(' ')]) 
        left_T = np.dot(np.linalg.inv(T_ins_matrix), left_T)
    with open(os.path.join(extrinsics_dir, 'velodyne_right.txt')) as extrinsics_file:
        extrinsics = next(extrinsics_file)
        right_T = build_se3_transform([float(x) for x in extrinsics.split(' ')])        
        right_T = np.dot(np.linalg.inv(T_ins_matrix), right_T)

    intensity_array = copy.deepcopy(pc_left[3,:])
    pc_left[3,:] = 1
    pc_left_ed = np.dot(left_T, pc_left)  
    pc_left[3,:] = intensity_array
    pc_left_ed[3,:] = intensity_array
    intensity_array = copy.deepcopy(pc_right[3,:])
    pc_right[3,:] = 1
    pc_right_ed = np.dot(right_T, pc_right)  
    pc_right[3,:] = intensity_array
    pc_right_ed[3,:] = intensity_array
    pc_cat = np.concatenate((pc_left_ed, pc_right_ed), axis=1)
    pc_cat = pc_cat.transpose()

    return pc_cat
    

# load lidar file in oxford radar robotcar dataset
def load_lidar_file_oxford_radar(file_path):
    if os.path.isfile(file_path):
        if 'bin' in file_path:
            lidar_pc_raw = load_velodyne_binary(file_path)
        else:
            ranges, intensities, angles, approximate_timestamps = load_velodyne_raw(file_path)
            lidar_pc_raw = velodyne_raw_to_pointcloud(ranges, intensities, angles)
    else:
        if 'bin' in file_path:
            file_path = file_path.replace('bin', 'png')
            ranges, intensities, angles, approximate_timestamps = load_velodyne_raw(file_path)
            lidar_pc_raw = velodyne_raw_to_pointcloud(ranges, intensities, angles)
        else:
            file_path = file_path.replace('png', 'bin')
            lidar_pc_raw = load_velodyne_binary(file_path)
      
    return lidar_pc_raw


def load_img_file_oxford(filename, cam_mode):
    assert os.path.exists(filename), f'Cannot access image file: {filename}'
    input_image = cv2.imread(filename)
    input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB)
    return input_image


class PointCloudWithImageLoader:
    # Generic point cloud loader class
    def __init__(self):
        # remove_zero_points: remove points with all zero coordinates
        # remove_ground_plane: remove points on ground plane level and below
        # ground_plane_level: ground plane level
        self.remove_zero_points = True
        self.remove_ground_plane = False
        self.ground_plane_level = None
        self.set_properties()

    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level. Must be defined in inherited classes.
        raise NotImplementedError('set_properties must be defined in inherited classes')

    def __call__(self, file_pathname, sph=False, extrinsics_dir=None):
        # Reads the point cloud from a disk and preprocess (optional removal of zero points and points on the ground
        # plane and below
        # file_pathname: relative file path

        if isinstance(file_pathname, str):
            assert os.path.exists(file_pathname), f"Cannot open point cloud: {file_pathname}"
            pc, imgs = self.read_pcim(file_pathname, sph, extrinsics_dir)
            if self.remove_zero_points:
                mask = np.all(np.isclose(pc, 0), axis=1)
                pc = pc[~mask]

            if self.remove_ground_plane:
                mask = pc[:, 2] > self.ground_plane_level
                pc = pc[mask]
        elif isinstance(file_pathname, list):
            for i in range(len(file_pathname)): 
                assert os.path.exists(file_pathname[i]), f"Cannot open point cloud: {file_pathname[i]}"
                pc, imgs = self.read_pcim(file_pathname, sph, extrinsics_dir)

                if self.remove_zero_points:
                    mask = np.all(np.isclose(pc, 0), axis=1)
                    mask = np.ravel(mask)
                    pc = pc[~mask]

                if self.remove_ground_plane:
                    mask = pc[:, 2] > self.ground_plane_level
                    mask = np.ravel(mask)
                    pc = pc[mask]
        else:
            raise NotImplementedError("read_pcim only support str and list input")

        return pc, imgs

    def read_pcim(self, file_pathname, sph=False, extrinsics_dir=None):
        # Reads the point cloud without pre-processing
        raise NotImplementedError("read_pcim must be overloaded in an inheriting class")


class PointCloudWithImageLoader_nopc:
    # Generic point cloud loader class
    def __init__(self):
        # remove_zero_points: remove points with all zero coordinates
        # remove_ground_plane: remove points on ground plane level and below
        # ground_plane_level: ground plane level
        self.remove_zero_points = True
        self.remove_ground_plane = False
        self.ground_plane_level = None
        self.set_properties()

    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level. Must be defined in inherited classes.
        raise NotImplementedError('set_properties must be defined in inherited classes')

    def __call__(self, file_pathname, sph=False, extrinsics_dir=None, IS_MONO=False):
        # Reads the point cloud from a disk and preprocess (optional removal of zero points and points on the ground
        # plane and below
        # file_pathname: relative file path

        if isinstance(file_pathname, str):
            assert os.path.exists(file_pathname), f"Cannot open point cloud: {file_pathname}"
            imgs = self.read_pcim_nopc(file_pathname, sph, extrinsics_dir, IS_MONO)
        elif isinstance(file_pathname, list):
            for i in range(len(file_pathname)): 
                assert os.path.exists(file_pathname[i]), f"Cannot open point cloud: {file_pathname[i]}"
                imgs = self.read_pcim_nopc(file_pathname, sph, extrinsics_dir, IS_MONO)
        else:
            raise NotImplementedError("read_pcim only support str and list input")

        return imgs

    def read_pcim_nopc(self, file_pathname, sph=False, extrinsics_dir=None, IS_MONO=False):
        # Reads the point cloud without pre-processing
        raise NotImplementedError("read_pcim must be overloaded in an inheriting class")


class OxfordPointCloudWithImageLoader(PointCloudWithImageLoader):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = 2.0
        self.remove_ground_plane = False

    def read_pcim(self, file_pathname: list, sph=False, extrinsics_dir=None) -> torch.Tensor:
        # Reads the point cloud without pre-processing
        # Returns Nx4 tensor
        # assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        left_velo_filename = file_pathname[0]
        right_velo_filename = file_pathname[1]

        pc_left = load_lidar_file_oxford_radar(left_velo_filename)
        pc_right = load_lidar_file_oxford_radar(right_velo_filename)
        pc = pc_concantate(pc_left, pc_right, extrinsics_dir)
        # pc = np.array(pc_concantate(pc_left, pc_right))
        
        # mask = (np.abs(pc[:,0]) < 70.) * (pc[:,2] > -28) * (pc[:,2] < self.ground_plane_level) \
        #     * (np.abs(pc[:,1]) < 70) * (np.linalg.norm(pc[:,:2]) > 2.)

        pc = pc[:, :3]
        mask = pc[:, 2] < self.ground_plane_level
        mask = np.ravel(mask)
        pc = pc[mask]

        camera_mode = ["mono_left", "mono_right", "mono_rear", ]
        images = [load_img_file_oxford(file_pathname[i], camera_mode[i-2]) for i in range(2, 5)]  # 0, 1 are radar

        return pc, images


class OxfordPointCloudWithImageLoader_nopc(PointCloudWithImageLoader_nopc):
    def set_properties(self):
        # Set point cloud properties, such as ground_plane_level.
        self.ground_plane_level = 2.0
        self.remove_ground_plane = False

    def read_pcim_nopc(self, file_pathname: list, sph=False, extrinsics_dir=None, IS_MONO=False) -> torch.Tensor:
        # # Reads the point cloud without pre-processing
        # # Returns Nx4 tensor
        # # assert extrinsics_dir is not None, 'need extrinsics_dir param for oxford dataset'

        # left_velo_filename = file_pathname[0]
        # right_velo_filename = file_pathname[1]

        # pc_left = load_lidar_file_oxford_radar(left_velo_filename)
        # pc_right = load_lidar_file_oxford_radar(right_velo_filename)
        # pc = pc_concantate(pc_left, pc_right, extrinsics_dir)
        # # pc = np.array(pc_concantate(pc_left, pc_right))
        
        # # mask = (np.abs(pc[:,0]) < 70.) * (pc[:,2] > -28) * (pc[:,2] < self.ground_plane_level) \
        # #     * (np.abs(pc[:,1]) < 70) * (np.linalg.norm(pc[:,:2]) > 2.)

        # pc = pc[:, :3]
        # mask = pc[:, 2] < self.ground_plane_level
        # mask = np.ravel(mask)
        # pc = pc[mask]

        camera_mode = ["mono_left", "mono_right", "mono_rear"]

        if IS_MONO:
            images = [load_img_file_oxford(file_pathname[i], camera_mode[i-2]) for i in range(4, 5)]  # 0, 1 are radar
        else:
            images = [load_img_file_oxford(file_pathname[i], camera_mode[i-2]) for i in range(2, 5)]  # 0, 1 are radar

        return images


class OxfordSequence(Dataset):
    """
    Dataset returns a point cloud from a train or test split from one sequence from a raw Mulran dataset
    """
    def __init__(self, dataset_root: str, sequence_name: str, split: str, dataset_item_range="0.0-3.0", pickle_name="pickle.txt", IS_MONO=False, NO_DEPTH=True):
        dataset_root = os.path.expanduser(dataset_root)
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test']

        self.dataset_root = dataset_root
        self.sequence_name = sequence_name
        self.split = split
        self.dataset_item_range = dataset_item_range
        self.IS_MONO = IS_MONO
        self.NO_DEPTH = NO_DEPTH

        sequence_path = os.path.join(self.dataset_root, self.sequence_name)
        self.sequence_path = sequence_path
        assert os.path.exists(sequence_path), f'Cannot access sequence: {sequence_path}'

        self.right_lidar_tsfile = os.path.join(sequence_path, 'velodyne_right.timestamps')
        self.mono_left_tsfile = os.path.join(sequence_path, 'mono_left.timestamps')
        self.mono_right_tsfile = os.path.join(sequence_path, 'mono_right.timestamps')
        self.mono_rear_tsfile = os.path.join(sequence_path, 'mono_rear.timestamps')
        self.right_lidar_ts = read_ts_file(self.right_lidar_tsfile)    
        self.mono_left_ts = read_ts_file(self.mono_left_tsfile)
        self.mono_right_ts = read_ts_file(self.mono_right_tsfile)
        self.mono_rear_ts = read_ts_file(self.mono_rear_tsfile)
        
        # Maximum discrepancy between timestamps of LiDAR scan and global pose in seconds
        self.pose_time_tolerance = 1.
  
        self.pose_file = os.path.join(sequence_path, 'gps/ins.csv')
        assert os.path.exists(self.pose_file), f'Cannot access ground truth file: {self.pose_file}'

        self.rel_left_lidar_path = os.path.join(self.sequence_name, 'velodyne_left')
        left_lidar_path = os.path.join(self.dataset_root, self.rel_left_lidar_path)
        assert os.path.exists(left_lidar_path), f'Cannot access left lidar scans: {left_lidar_path}'

        self.pcim_loader = OxfordPointCloudWithImageLoader()
        self.pcim_loader_nopc = OxfordPointCloudWithImageLoader_nopc()

        self.timestamps, self.poses, self.poses_RPY = read_lidar_poses_RPY(self.pose_file, left_lidar_path, self.pose_time_tolerance)
        self.xys = self.poses[:, :2, 3]

        self.rel_scan_filepath = [os.path.join(self.rel_left_lidar_path, str(e) + '.bin') for e in self.timestamps]

        self.extrinsics_dir = os.path.join(self.dataset_root, 'extrinsics')

        if self.split == "train":
            self.save_pickle_dir = pickle_name
            self.pickle = pickle.load(open(self.save_pickle_dir, 'rb'))
            self.nearby_points = self.pickle[0]
            self.nearby_points_R = self.pickle[1]

        filepaths = []
        pop_list = []
        poses_spl = []
        for idx in range(len(self.rel_scan_filepath)):
            file_valid = self.get_filepaths(idx)
            if file_valid is None:
                pop_list.append(idx)
            else:
                filepaths.append(file_valid)
    
        self.filepaths = filepaths
        self.poses = np.delete(self.poses, pop_list, 0)
        print("raw data:", len(self.timestamps))
        self.timestamps = np.delete(self.timestamps, pop_list)
        print("valid data:", len(self.timestamps))
        
        self.rel_scan_filepath = np.delete(self.rel_scan_filepath, pop_list)

        if self.split == "test":
            if self.dataset_item_range == "0.0-4.0":
                self.rel_scan_filepath = self.rel_scan_filepath[::8]
                self.timestamps = self.timestamps[::8]
                self.poses = self.poses[::8]
                self.poses_RPY = self.poses_RPY[::8]
                self.xys = self.xys[::8]
    
        assert len(self.timestamps) == len(self.poses)
        assert len(self.timestamps) == len(self.poses_RPY)
        assert len(self.timestamps) == len(self.rel_scan_filepath)
        print(f'{len(self.timestamps)} scans in {sequence_name}-{split}')

    def __len__(self):
        if self.split == "train":
            return len(self.rel_scan_filepath)
        if self.split == "test":
            return len(self.rel_scan_filepath) - 1

    def __getitem__(self, idx):
        filepaths = self.get_filepaths(idx)
        all_2_5_images = []
        all_2_5_depth = []

        if self.IS_MONO:
            folder_paths_depth = [os.path.normpath(os.path.join(self.sequence_path, "./depth_mono_rear_rect"))]
        else:
            folder_paths_depth = [
                os.path.normpath(os.path.join(self.sequence_path, "./depth_mono_left_rect")),
                os.path.normpath(os.path.join(self.sequence_path, "./depth_mono_right_rect")),
                os.path.normpath(os.path.join(self.sequence_path, "./depth_mono_rear_rect"))]

        if self.split == "train":
            idx1 = idx

            correct_idx2_list = []
            correct_idx2_list_rot = []

            correct_idx2_list = self.nearby_points[idx1]
            correct_idx2_list_rot = self.nearby_points_R[idx1]

            if len(correct_idx2_list_rot) != 0 and len(correct_idx2_list) != 0:
                if random.randint(1, 10) <= 7:
                    idx2 = random.choice(correct_idx2_list_rot)
                else:
                    idx2 = random.choice(correct_idx2_list)
            elif len(correct_idx2_list_rot) != 0:
                idx2 = random.choice(correct_idx2_list_rot)
            elif len(correct_idx2_list) != 0:
                idx2 = random.choice(correct_idx2_list)
            else:
                while len(correct_idx2_list) == 0 and len(correct_idx2_list_rot) == 0:
                    idx1 = random.randint(0, len(self)-1)
                    correct_idx2_list = self.nearby_points[idx1]
                    correct_idx2_list_rot = self.nearby_points_R[idx1]
                    if len(correct_idx2_list_rot) != 0 and len(correct_idx2_list) != 0:
                        if random.randint(1, 10) <= 7:
                            idx2 = random.choice(correct_idx2_list_rot)
                        else:
                            idx2 = random.choice(correct_idx2_list)
                    elif len(correct_idx2_list_rot) != 0:
                        idx2 = random.choice(correct_idx2_list_rot)
                    elif len(correct_idx2_list) != 0:
                        idx2 = random.choice(correct_idx2_list)

        if self.split == "test":
            idx1 = idx
            idx2 = idx + 1

        poses = np.zeros((2, 4, 4), dtype=np.float64)
        poses_yaw_x_y = [[.0, .0, .0], [.0, .0, .0]]
        timestamp = None
        for ndx_now, idx_temp in enumerate([idx1, idx2]):
            all_5_images = []
            filepaths = self.get_filepaths(idx_temp)
            images = self.pcim_loader_nopc(filepaths, extrinsics_dir=self.extrinsics_dir, IS_MONO=self.IS_MONO)
            tensors = self.images_to_tensor(images)
            all_5_images = torch.stack(tensors)
            all_2_5_images.append(all_5_images)

            if timestamp is None:
                timestamp = float(self.timestamps[idx_temp])
            poses[ndx_now] = self.poses[idx_temp]

            depth_maps = []
            if self.NO_DEPTH:
                if self.IS_MONO:
                    depth_map = torch.zeros_like(tensors[0][0])
                    depth_maps.append(depth_map)
                    all_2_5_depth.append(torch.stack(depth_maps))
                else:
                    for tensor in tensors:
                        depth_map = torch.zeros_like(tensor[0])
                        depth_maps.append(depth_map)
                    all_2_5_depth.append(torch.stack(depth_maps))
            else:
                image_name = self.rel_scan_filepath[idx_temp].split('.')[0].split('/')[-1]
                if self.IS_MONO:
                    for cam_num in range(1):
                        file_path = os.path.normpath(os.path.join(folder_paths_depth[cam_num], f"{image_name}.npy"))
                        depth_map = np.load(file_path)
                        depth_map = torch.tensor(depth_map, dtype=torch.float)
                        depth_maps.append(depth_map)
                    all_2_5_depth.append(torch.stack(depth_maps))
                else:
                    for cam_num in range(3):
                        file_path = os.path.normpath(os.path.join(folder_paths_depth[cam_num], f"{image_name}.npy"))
                        depth_map = np.load(file_path)
                        depth_map = torch.tensor(depth_map, dtype=torch.float)
                        depth_maps.append(depth_map)
                    all_2_5_depth.append(torch.stack(depth_maps))

        all_2_5_images = torch.stack(all_2_5_images)
        all_2_5_depth = torch.stack(all_2_5_depth)

        if self.split == "train":
            return all_2_5_images, poses, all_2_5_depth, timestamp, idx1, idx2
        else:
            return all_2_5_images, poses, all_2_5_depth, timestamp

    def get_filepaths(self, ndx):
        reading_left_lidar_filepath = os.path.join(self.dataset_root, self.rel_scan_filepath[ndx])
        timestamps = self.timestamps[ndx]

        right_lidar_ndx = find_nearest_ndx(timestamps, self.right_lidar_ts)
        mono_left_ndx = find_nearest_ndx(timestamps, self.mono_left_ts)
        mono_right_ndx = find_nearest_ndx(timestamps, self.mono_right_ts)
        mono_rear_ndx = find_nearest_ndx(timestamps, self.mono_rear_ts)
        
        right_lidar_timestamp = self.right_lidar_ts[right_lidar_ndx]
        mono_left_timestamp = self.mono_left_ts[mono_left_ndx]
        mono_right_timestamp = self.mono_right_ts[mono_right_ndx]
        mono_rear_timestamp = self.mono_rear_ts[mono_rear_ndx]

        reading_right_lidar_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'velodyne_right')
        reading_mono_left_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_left_rect')
        reading_mono_right_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_right_rect')
        reading_mono_rear_filepath = reading_left_lidar_filepath.replace('velodyne_left', 'mono_rear_rect')

        reading_mono_left_filepath = reading_mono_left_filepath.replace('bin', 'png')
        reading_mono_right_filepath = reading_mono_right_filepath.replace('bin', 'png')
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace('bin', 'png')

        reading_right_lidar_filepath = reading_right_lidar_filepath.replace(str(timestamps), str(right_lidar_timestamp))
        reading_mono_left_filepath = reading_mono_left_filepath.replace(str(timestamps), str(mono_left_timestamp))
        reading_mono_right_filepath = reading_mono_right_filepath.replace(str(timestamps), str(mono_right_timestamp))
        reading_mono_rear_filepath = reading_mono_rear_filepath.replace(str(timestamps), str(mono_rear_timestamp))

        filepaths = [reading_left_lidar_filepath, reading_right_lidar_filepath, reading_mono_left_filepath, reading_mono_right_filepath, reading_mono_rear_filepath]

        return filepaths

    def load_pcs(self, scan_paths):
        # Load point cloud from file
        pcs = []
        for scan_path in scan_paths:
            pc = load_lidar_file_oxford_radar(scan_path)
            if len(pc) == 0:
                continue
            pcs.append(pc)
        pcs = np.array(pcs)
        return pcs

    def images_to_tensor(self, images):
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        tensors = [transform(image) for image in images]
        return tensors

    def project_vel_to_cam_oxford(self, hits, cam_num):
        # Load camera parameters
        image_meata_path = os.path.join(data_oxford_dir, "image_meta.pkl")
        with open(image_meata_path, 'rb') as handle:
            image_meta = pickle.load(handle)

        intrins = np.array(image_meta['K'])
        cams_T_body = np.array(image_meta['T'])
        K = intrins[cam_num]
        T_camNormal_body = cams_T_body[cam_num]
        hits_c = np.matmul(T_camNormal_body, hits)
        hits_im = np.matmul(K, hits_c[0:3, :])

        return hits_im


class OxfordSequences(Dataset):
    """
    Multiple Oxford sequences indexed as a single dataset. Each element is identified by a unique global index.
    """
    def __init__(self, dataset_root: str, sequence_names: List[str], split: str, dataset_item_range="0.0-3.0", pickle_names=["pickle.txt"], IS_MONO=False, NO_DEPTH=True):
        assert len(sequence_names) > 0
        assert os.path.exists(dataset_root), f'Cannot access dataset root: {dataset_root}'
        assert split in ['train', 'test', 'save_gt', 'save_pickle']

        self.dataset_root = dataset_root
        self.split = split
        self.IS_MONO = IS_MONO
        self.NO_DEPTH = NO_DEPTH

        sequences = []
        for seq_name, pickle_name in zip(sequence_names, pickle_names):
            ds = OxfordSequence(self.dataset_root, seq_name, split=split, dataset_item_range=dataset_item_range, pickle_name=pickle_name, IS_MONO=self.IS_MONO, NO_DEPTH=NO_DEPTH)
            sequences.append(ds)
            print(f'!!!!!!more_sequences: {len(ds)} scans in {seq_name}-{split}!!!!!!')

        self.dataset = ConcatDataset(sequences)

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, ndx):
        return self.dataset[ndx]
